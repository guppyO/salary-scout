name: Check BLS Data Update

on:
  # Run every Monday at 9 AM UTC (during BLS business hours)
  schedule:
    - cron: '0 9 * * 1'

  # Also allow manual trigger
  workflow_dispatch:

env:
  NODE_VERSION: '20'

jobs:
  check-for-update:
    runs-on: ubuntu-latest
    outputs:
      has_update: ${{ steps.check.outputs.has_update }}
      latest_period: ${{ steps.check.outputs.latest_period }}
      download_url: ${{ steps.check.outputs.download_url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Check for BLS update
        id: check
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          # Run the check script - exit code 1 means update available
          set +e
          npx tsx scripts/check-bls-update.ts
          EXIT_CODE=$?
          set -e

          if [ $EXIT_CODE -eq 1 ]; then
            echo "has_update=true" >> $GITHUB_OUTPUT
          else
            echo "has_update=false" >> $GITHUB_OUTPUT
          fi

  update-data:
    runs-on: ubuntu-latest
    needs: check-for-update
    if: needs.check-for-update.outputs.has_update == 'true'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download new BLS data
        run: |
          mkdir -p data/temp
          DOWNLOAD_URL="${{ needs.check-for-update.outputs.download_url }}"
          echo "Downloading from: $DOWNLOAD_URL"
          curl -L -o data/temp/oews-data.zip "$DOWNLOAD_URL"

          # Extract the ZIP file
          cd data/temp
          unzip oews-data.zip

          # Find the MSA file (metropolitan salary data)
          MSA_FILE=$(find . -name "*MSA*.xlsx" | head -1)
          echo "Found MSA file: $MSA_FILE"

          # Move to expected location
          mkdir -p ../oesm_latest
          cp "$MSA_FILE" ../oesm_latest/MSA_data.xlsx

          # Cleanup
          cd ..
          rm -rf temp

      - name: Run data ingestion
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          DATA_FILE: data/oesm_latest/MSA_data.xlsx
          DATA_PERIOD: ${{ needs.check-for-update.outputs.latest_period }}
        run: |
          echo "Ingesting data for period: $DATA_PERIOD"
          npx tsx scripts/ingest-data.ts

      - name: Deploy to Vercel
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}
          VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }}
        run: |
          npm i -g vercel
          vercel pull --yes --environment=production --token=$VERCEL_TOKEN
          vercel build --prod --token=$VERCEL_TOKEN
          vercel deploy --prebuilt --prod --token=$VERCEL_TOKEN

      - name: Notify success
        run: |
          echo "âœ… Successfully updated to ${{ needs.check-for-update.outputs.latest_period }}"
          echo "ðŸš€ Deployed to production"

  notify-no-update:
    runs-on: ubuntu-latest
    needs: check-for-update
    if: needs.check-for-update.outputs.has_update == 'false'

    steps:
      - name: Log status
        run: |
          echo "âœ“ No BLS data update available"
          echo "Current data is up to date"
